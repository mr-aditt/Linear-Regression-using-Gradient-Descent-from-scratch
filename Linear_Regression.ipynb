{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SOu_uplI2TT7"
      ],
      "authorship_tag": "ABX9TyNSF+OxYxO5RVPm2WdvdrcE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-aditt/Linear-Regression-using-Gradient-Descent-from-scratch/blob/main/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0Lgix9aszAm"
      },
      "source": [
        "# **Linear Regression**\n",
        "\n",
        "Implemented a linear Regression Model using Batch Gradient Descent and Stochastic Gradient Descent from scratch. Then compared our model with sklearn's Linear Regression Model on the basis of metric called \"mean squared error\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qyWoKyZ6QMO"
      },
      "source": [
        "**Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJmwO6CO4a5L"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression as Sk_linear_reg\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOu_uplI2TT7"
      },
      "source": [
        "#I. Initial Step\n",
        "1. Create User-defined Class for Regression\n",
        "2. Import and understand dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGzI_-HQ6duh"
      },
      "source": [
        "**User-defined Regression Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6QVr6Rn6YgR"
      },
      "source": [
        "import numpy as np\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "class LinearRegression:\n",
        "\n",
        "    def __init__(self, lr=0.01, max_iter=100_000, optimizer='bgd', batch_size=128, copy_x=True):\n",
        "        \"\"\"\n",
        "        :param lr: float, Learning Rate\n",
        "        :param max_iter: int, Max number of iteration or epochs\n",
        "        :param optimizer: str, 'bgd' <- Batch Gradient Descent\n",
        "                                'sgd' <- Stochastic Gradient Descent\n",
        "        :param batch_size: int, Partition training set into small batch size. Applicable only when\n",
        "                                optimizer = 'sgd'\n",
        "        :param copy_x: int, Make a copy of predictors\n",
        "        \"\"\"\n",
        "\n",
        "        self.coef_ = 0.0 \n",
        "        self.intercept_ = 0.0\n",
        "        self.error_ = list()\n",
        "        self.lr = lr\n",
        "        self.max_iter = max_iter\n",
        "        self.optimizer = optimizer.lower()\n",
        "        self.batch_size = batch_size if self.optimizer == 'sgd' else None\n",
        "        self.copy_x = copy_x\n",
        "    \n",
        "    @staticmethod\n",
        "    def mse(y_actual, y_predicted):\n",
        "        \"\"\"\n",
        "        This method calculates the Mean Squared Error.\n",
        "        :param y_actual: Array, True response\n",
        "        :param y_predicted: Array, Predicted response\n",
        "        :return: float, Amount of error\n",
        "        \"\"\"\n",
        "        return (1/len(y_actual))*sum((y_actual-y_predicted)**2)\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(y_actual, y_predicted):\n",
        "        \"\"\"\n",
        "        This method calculates the Root Mean Squared Error.\n",
        "        :param y_actual: Array, True response\n",
        "        :param y_predicted: Array, Predicted response\n",
        "        :return: float, Square root of amount of error\n",
        "        \"\"\"\n",
        "        print(type(y_actual))\n",
        "        return sqrt((1/len(y_actual))*sum((y_actual-y_predicted)**2))\n",
        "    \n",
        "    def bgd(self, x, y):\n",
        "        \"\"\"\n",
        "        This is Batch Gradient Descent.\n",
        "        :param x: Array [n_instances, n_features], Predictors\n",
        "        :param y: Array [n_instances,], Response\n",
        "        \"\"\"\n",
        "        # 1. Predict y for each instance dataset. y_hat dimension [n_instances,]\n",
        "        y_hat = np.dot(x, self.coef_) + self.intercept_\n",
        "        \n",
        "        # 2. Calculate Loss for current epoch or iteration\n",
        "        loss = self.mse(y, y_hat)\n",
        "        self.error_.append(loss)\n",
        "        \n",
        "        # 3. Calculate the amount of change needed in\n",
        "        # coefficients and intercept to reduce the loss.\n",
        "        j_coef = (-2 / x.shape[0]) * np.dot(x.T, (y - y_hat))\n",
        "        j_intercept = (-2 / x.shape[0]) * np.sum(y - y_hat)\n",
        "\n",
        "        # 4. Update the coefficients and intercept\n",
        "        #  with that change \n",
        "        self.coef_ -= self.lr * j_coef\n",
        "        self.intercept_ -= self.lr * j_intercept\n",
        "    \n",
        "    def sgd(self, x, y):\n",
        "        \"\"\"\n",
        "        This is Stochastic Gradient Descent. Per iteration, sgd runs for (n_instances by batch_size) times\n",
        "        :param x: Array [n_instances, n_features], Predictors\n",
        "        :param y: Array [n_instances,], Response\n",
        "        \"\"\"\n",
        "        start = 0\n",
        "        end = self.batch_size\n",
        "        j_coef, j_intercept, loss = 0.0, 0.0, 0.0\n",
        "\n",
        "        # This loop runs for ceiling(n_instances by batch_size) times\n",
        "        while end < x.shape[0]:\n",
        "            y_hat = np.dot(x[start:end, :], self.coef_) + self.intercept_\n",
        "            loss += self.mse(y[start:end], y_hat)\n",
        "\n",
        "            # Accumulate the amount of change needed to get closer to local minima.\n",
        "            j_coef += (-2 / self.batch_size) * np.dot(x[start:end, :].T, (y[start:end] - y_hat))\n",
        "            j_intercept += (-2 / self.batch_size) * np.sum(y[start:end] - y_hat)\n",
        "            start = end\n",
        "            end += self.batch_size\n",
        "\n",
        "        self.error_.append(loss)    \n",
        "\n",
        "        # Update coefficients and intercept with the amount of change needed\n",
        "        # to get closer to local minima\n",
        "        self.coef_ -= self.lr * j_coef\n",
        "        self.intercept_ -= self.lr * j_intercept\n",
        "    \n",
        "    def fit(self, x, y):\n",
        "        \"\"\"\n",
        "        This method fits the Regression line on dataset by calling either\n",
        "        bgd or sgd for max_iter times.\n",
        "        :param x: Array [n_instances, n_features], Predictors\n",
        "        :param y: Array [n_instances,], Response\n",
        "        \"\"\"\n",
        "        x = np.asarray(x)\n",
        "        y = np.asarray(y)\n",
        "        x_copy = x.copy() if self.copy_x is True else x\n",
        "        self.coef_ = np.zeros(x_copy.shape[1])\n",
        "\n",
        "        # Run for max_iter times and calculate optimal coefficients\n",
        "        # and intercept value\n",
        "        for e in range(self.max_iter):\n",
        "            if self.optimizer == 'bgd':\n",
        "                self.bgd(x_copy, y)\n",
        "            elif self.optimizer == 'sgd':\n",
        "                self.sgd(x_copy, y)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        This method predict the response for predictors based on fitted line's\n",
        "        coefficients and intercept.\n",
        "        :param x: Array, Predictor\n",
        "        :return: Array, Predicted response\n",
        "        \"\"\"\n",
        "        x = np.asarray(x)\n",
        "        return np.dot(x, self.coef_) + self.intercept_\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'\\n\\nLinearRegression{self.coef_, self.intercept_, self.lr, self.max_iter, self.optimizer}'\n",
        "    \n",
        "    def __str__(self):\n",
        "        return '\\n\\nClassifier: Linear Regression\\nAttributes:\\n\\tcoefficient: {} \\n\\tintercept: {:.2f} ' \\\n",
        "               '\\n\\tlearning_rate: {} \\n\\tepochs: {:,} \\n\\toptimizer: {}'.format(self.coef_, self.intercept_, self.lr,\n",
        "                                                                                 self.max_iter, self.optimizer)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGK8PgFO104T"
      },
      "source": [
        "**Looking at dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okc5-OKk6rW-",
        "outputId": "3bc889d6-af61-4a29-b232-356e03e0b760"
      },
      "source": [
        "data = load_diabetes()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "print('Describe Dataset\\n', df.describe())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Describe Dataset\n",
            "                 age           sex  ...            s6      target\n",
            "count  4.420000e+02  4.420000e+02  ...  4.420000e+02  442.000000\n",
            "mean  -3.634285e-16  1.308343e-16  ... -3.412882e-16  152.133484\n",
            "std    4.761905e-02  4.761905e-02  ...  4.761905e-02   77.093005\n",
            "min   -1.072256e-01 -4.464164e-02  ... -1.377672e-01   25.000000\n",
            "25%   -3.729927e-02 -4.464164e-02  ... -3.317903e-02   87.000000\n",
            "50%    5.383060e-03 -4.464164e-02  ... -1.077698e-03  140.500000\n",
            "75%    3.807591e-02  5.068012e-02  ...  2.791705e-02  211.500000\n",
            "max    1.107267e-01  5.068012e-02  ...  1.356118e-01  346.000000\n",
            "\n",
            "[8 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxXK6uYy2thv"
      },
      "source": [
        "#II. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGsHDwr92CVb"
      },
      "source": [
        "**Create, Train, Predict and Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfXSih7b64IS",
        "outputId": "ceff828f-ee39-4f6a-bb58-d67c7cb154fb"
      },
      "source": [
        "epoch = 10_000\n",
        "my_clf = LinearRegression(max_iter=epoch, optimizer='bgd')\n",
        "reg_clf = Sk_linear_reg()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.drop(['target'], axis=1), df['target'], test_size=0.3)\n",
        "my_clf.fit(x_train, y_train)\n",
        "reg_clf.fit(x_train, y_train)\n",
        "\n",
        "my_pred = my_clf.predict(x_test)\n",
        "reg_pred = reg_clf.predict(x_test)\n",
        "\n",
        "print(f\"User-defined Model's MSE: {my_clf.mse(y_test, my_pred):.3f}\")\n",
        "print(f\"Sklearn Model's MSE: {mean_squared_error(y_test, reg_pred):.3f}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User-defined Model's MSE: 3427.681\n",
            "Sklearn Model's MSE: 2926.988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "NKt0knnR7nDi",
        "outputId": "f0d9af32-afa6-447a-ec73-bc81f3a41e8d"
      },
      "source": [
        "plt.title(\"Error in K-epochs\")\n",
        "plt.plot(range(epoch), my_clf.error_, 'r-')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}